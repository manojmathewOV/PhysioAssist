# De Bono 6 Hats Analysis - PhysioAssist Roadmap
## Rigorous Critical Analysis with Introspection

> **Date:** November 8, 2025
> **Focus:** Robustness, Stability, Accuracy, Performance, Simplicity
> **Critical Requirement:** YouTube Template Comparison Accuracy

---

## ðŸŽ© White Hat: Facts & Data

### Current State Facts

**Core Functionality (Critical):**
- YouTube template comparison is THE core value proposition
- Patient video vs therapist-selected YouTube video comparison
- Goniometry (joint angle measurement) accuracy is make-or-break
- Real-time feedback requires <100ms end-to-end latency

**Existing Implementation:**
- Pose detection: MoveNet Lightning (17 keypoints)
- Comparison service: `comparisonAnalysisService.ts`
- Goniometry service: `goniometerService.ts`
- Error detection: shoulder, knee, elbow modules

**Missing from Current Roadmap:**
- âŒ No dedicated gate for YouTube template comparison validation
- âŒ No goniometry accuracy benchmarking against ground truth
- âŒ No end-to-end performance profiling (camera â†’ comparison â†’ feedback)
- âŒ No simplicity metrics (cognitive load, steps to complete task)
- âŒ No validation of comparison algorithm accuracy

**Metrics That Matter:**
1. **Pose Estimation Accuracy:** Â±5Â° joint angle error vs optical motion capture
2. **Goniometry Accuracy:** Â±3Â° vs physical goniometer measurements
3. **Comparison Accuracy:** Cohen's Îº â‰¥0.6 vs PT assessment
4. **Performance:** <100ms latency (camera â†’ pose â†’ angles â†’ comparison)
5. **Simplicity:** â‰¤5 steps from app open to feedback received
6. **Robustness:** 0 crashes in 100 patient sessions

---

## â¤ï¸ Red Hat: Emotions & Intuition

### Patient Perspective (Gut Feelings)

**What patients fear:**
- "Is this really measuring my movement correctly?"
- "Am I doing this wrong or is the app broken?"
- "This is too complicated, I give up"
- "It's too slow, I'll just skip it"

**What patients need to feel:**
- âœ… Confidence: "I trust this is accurate"
- âœ… Clarity: "I understand what to do"
- âœ… Control: "I can fix issues myself (lighting, distance)"
- âœ… Progress: "I can see I'm improving"

### Developer Perspective (Intuition)

**Red flags in current roadmap:**
- Gate sequence doesn't follow critical path (YouTube comparison buried in later gates)
- Too much focus on infrastructure (telemetry, device health) before core accuracy validated
- Smoothing integration (Gate 2) happens before we know if base pose detection is accurate enough
- Risk: We optimize performance of inaccurate measurements

**What feels right:**
- âœ… Validate accuracy FIRST, then optimize performance
- âœ… YouTube comparison should be Gate 1 (not buried)
- âœ… Every gate should have simplicity check
- âœ… Real-time performance should be tested continuously, not at end

---

## ðŸ–¤ Black Hat: Risks & Critical Flaws

### Critical Risks in Current Roadmap

**Risk 1: YouTube Comparison Accuracy Unvalidated**
- **Problem:** No dedicated gate validates comparison against YouTube templates
- **Impact:** Could ship app that compares inaccurately â†’ patient injury
- **Severity:** CRITICAL
- **Current mitigation:** None explicit
- **Needed:** Gate dedicated to YouTube template comparison validation

**Risk 2: Goniometry Accuracy Unknown**
- **Problem:** `goniometerService.ts` exists but accuracy never validated against ground truth
- **Impact:** Joint angles could be Â±10-15Â° off â†’ useless feedback
- **Severity:** CRITICAL
- **Current mitigation:** None
- **Needed:** Validate against physical goniometer or optical motion capture

**Risk 3: Performance Bottlenecks Discovered Late**
- **Problem:** Performance testing happens at Gate 9 (near end)
- **Impact:** Discover app is too slow after months of development
- **Severity:** HIGH
- **Current mitigation:** Some benchmarks in individual gates
- **Needed:** End-to-end performance gate early (after Gate 2)

**Risk 4: Simplicity vs Functionality Trade-off Not Managed**
- **Problem:** No metric for simplicity, no gate checks cognitive load
- **Impact:** App becomes complex, patients abandon
- **Severity:** HIGH
- **Current mitigation:** None
- **Needed:** Simplicity metrics at each gate (steps to feedback, cognitive load)

**Risk 5: Real-time Feedback Latency Not Architected**
- **Problem:** Many async operations (pose detection, smoothing, comparison, feedback) but no latency budget
- **Impact:** Feedback delayed by 500ms+ â†’ feels broken to patient
- **Severity:** HIGH
- **Current mitigation:** Individual component benchmarks (<50ms)
- **Needed:** End-to-end latency budget and profiling

**Risk 6: Pose Detection Model Mismatch**
- **Problem:** MoveNet (17-point) vs MediaPipe (33-point) confusion, new thresholds assume 33-point
- **Impact:** Clinical thresholds don't map correctly â†’ false positives/negatives
- **Severity:** CRITICAL
- **Current mitigation:** Adapter planned in Gate 3
- **Needed:** Resolve BEFORE any accuracy validation

**Risk 7: No Synthetic Test Dataset**
- **Problem:** Testing requires manual recording of exercises
- **Impact:** Can't systematically test all error types, lighting conditions, body types
- **Severity:** MEDIUM
- **Current mitigation:** None
- **Needed:** Synthetic video library with ground truth annotations

---

## ðŸ’› Yellow Hat: Optimism & Benefits

### What's Strong in Current Roadmap

**âœ… Research-Backed Approach:**
- One-Euro filter (ACM CHI 2012) - proven algorithm
- Clinical thresholds from AAOS, IJSPT, JOSPT - credible sources
- Persistence filtering - reduces false positives

**âœ… Comprehensive Testing Strategy:**
- Testing Gates 0-4 cover toolchain, logic, integration, clinical, ops
- Unit test coverage â‰¥95%
- Mutation testing ensures test quality

**âœ… Progressive Validation:**
- Gates build on each other
- Can't proceed without meeting exit criteria
- Reduces risk of late-stage failures

**âœ… Real Implementation (No Mocks):**
- Explicit focus on removing all mocks/stubs
- Real VisionCamera integration
- Real device health monitoring

### Opportunities for Enhancement

**âœ… YouTube Comparison as Core:**
- If we make comparison accuracy the FIRST gate, everything else supports it
- Clear north star: "Does comparison work accurately?"

**âœ… Performance-First Architecture:**
- If we measure end-to-end latency early, can architect for speed from start
- Avoid costly refactoring later

**âœ… Simplicity as Feature:**
- If we measure steps/cognitive load at each gate, ensure simplicity by design
- Not bolted on at end

---

## ðŸ’š Green Hat: Creativity & Alternatives

### Alternative Gate Structures

**Option A: Accuracy-First Roadmap**
```
Gate 1: Pose Detection Accuracy Validation
Gate 2: Goniometry Accuracy Validation
Gate 3: YouTube Comparison Accuracy Validation
Gate 4: Real-time Performance Optimization
Gate 5: Simplicity & UX Hardening
Gate 6: Robustness & Edge Cases
Gate 7: Beta Field Trial
```

**Option B: Critical Path Roadmap**
```
Gate 1: End-to-End Pipeline (Camera â†’ Pose â†’ Compare â†’ Feedback)
Gate 2: Accuracy Validation (all components)
Gate 3: Performance Optimization (<100ms latency)
Gate 4: Simplicity Validation (â‰¤5 steps)
Gate 5: Robustness Testing (edge cases, failures)
Gate 6: Beta Field Trial
```

**Option C: Hybrid (Recommended)**
```
Gate 0: Toolchain Sanity
Gate 1: Core Pipeline (Camera â†’ Pose â†’ Goniometry â†’ Compare) - REAL implementations
Gate 2: Accuracy Validation (Pose Â±5Â°, Goniometry Â±3Â°, Comparison Îºâ‰¥0.6)
Gate 3: Performance Optimization (End-to-end <100ms)
Gate 4: Smoothing & Clinical Thresholds (reduce false positives)
Gate 5: Simplicity & UX (â‰¤5 steps, cognitive load)
Gate 6: Robustness & Device Adaptation (thermal, memory, lighting)
Gate 7: Features (Templates, Prescription API, Auth)
Gate 8: Comprehensive Testing (all edge cases)
Gate 9: Beta Field Trial
```

### Creative Solutions

**Synthetic Test Dataset:**
- Use Blender + physics sim to generate synthetic exercise videos
- Ground truth: exact joint angles known
- Test all error types: valgus, hiking, hyperextension
- Test all conditions: lighting, occlusion, clothing

**Latency Budget System:**
- Total budget: 100ms
- Camera capture: 33ms (30 FPS)
- Pose detection: 30ms
- Goniometry: 5ms
- Comparison: 10ms
- Smoothing: 5ms
- Feedback generation: 10ms
- Rendering: 7ms
- Each component gets allocation, must stay under

**Simplicity Scorecard:**
- Steps to first feedback: â‰¤5
- Taps to complete exercise: â‰¤8
- Cognitive load (0-10 scale): â‰¤3 (tested with 5 users)
- Error recovery steps: â‰¤2

**Performance CI Gates:**
- Every PR runs end-to-end performance test
- Fails if >10% regression from baseline
- Prevents gradual performance degradation

---

## ðŸ”µ Blue Hat: Process & Meta-Analysis

### What's Wrong with Current Roadmap Structure

**Problem 1: Wrong Priority Order**
- Infrastructure (CI, telemetry, device health) comes before core functionality validation
- Risk: Optimize infrastructure for an inaccurate core

**Problem 2: YouTube Comparison Not Explicit**
- Comparison is THE core feature but isn't a dedicated gate
- Buried in general "error detection" gates
- Risk: Ship app that captures pose accurately but compares poorly

**Problem 3: No Continuous Performance Validation**
- Performance tested per component, not end-to-end
- Risk: Components are fast individually but slow together

**Problem 4: Simplicity Not Measured**
- No metrics, no validation, not in exit criteria
- Risk: Complex app, poor adoption

**Problem 5: Accuracy Validated Too Late**
- Pose accuracy not validated until after smoothing integrated
- Risk: Smooth inaccurate data â†’ still inaccurate

### Recommended Process Changes

**Change 1: Accuracy-First Gate Ordering**
```
1. Core accuracy (pose, goniometry, comparison)
2. Performance (real-time <100ms)
3. Simplicity (UX, cognitive load)
4. Robustness (edge cases, device adaptation)
5. Features (nice-to-haves)
```

**Change 2: Continuous Performance Profiling**
- Add performance test to every gate's exit criteria
- Track cumulative latency: Gate 1 (50ms) â†’ Gate 2 (70ms) â†’ Gate 3 (90ms) â†’ budget limit 100ms
- Fail gate if budget exceeded

**Change 3: Simplicity Metrics**
- Add to every gate: "Steps to feedback â‰¤5", "Cognitive load â‰¤3"
- User test with 3 people per gate
- Simplify before proceeding

**Change 4: YouTube Comparison as Gate 1**
- Make it explicit, make it first (after toolchain)
- Validate end-to-end: YouTube video â†’ pose extraction â†’ angle calculation â†’ patient video â†’ comparison â†’ error detection
- Don't proceed until this works accurately

---

## ðŸŽ¯ Synthesis: Critical Requirements Analysis

### Requirement 1: Robustness & Stability

**Current Gaps:**
- âŒ No synthetic test dataset (can't test all scenarios)
- âŒ Edge cases tested late (Gate 9)
- âŒ Device adaptation tested late (Gate 4)

**Needed:**
- âœ… Synthetic video library (Gate 1)
- âœ… Edge case testing per gate (not batched at end)
- âœ… Device profiling early (Gate 2)

### Requirement 2: End User Ease of Use

**Current Gaps:**
- âŒ No simplicity metrics
- âŒ No cognitive load testing
- âŒ No step counting

**Needed:**
- âœ… Simplicity scorecard at each gate
- âœ… User testing (3 people) per gate
- âœ… Maximum 5 steps to feedback

### Requirement 3: Accuracy of Data Capture & Pose Estimation

**Current Gaps:**
- âŒ Pose accuracy not validated against ground truth
- âŒ No optical motion capture comparison
- âŒ No physical goniometer validation

**Needed:**
- âœ… Gate 1: Validate pose accuracy (Â±5Â° vs Vicon or synthetic ground truth)
- âœ… Gate 2: Validate goniometry (Â±3Â° vs physical goniometer)
- âœ… Continuous accuracy regression testing

### Requirement 4: Goniometry Accuracy

**Current Gaps:**
- âŒ `goniometerService.ts` exists but never validated
- âŒ No comparison against physical measurements
- âŒ No validation of calculation methods (3-point angle, quaternions, etc.)

**Needed:**
- âœ… Dedicated goniometry validation gate
- âœ… Test against known joint angles (synthetic or physical rig)
- âœ… Document calculation method with academic sources

### Requirement 5: YouTube Comparison Capability (CRITICAL)

**Current Gaps:**
- âŒ No dedicated gate for comparison validation
- âŒ Comparison algorithm not validated against PT assessments
- âŒ No systematic testing of all error types
- âŒ Temporal alignment (DTW vs speedRatio) not validated

**Needed:**
- âœ… Gate 1: YouTube comparison as FIRST major gate
- âœ… Validate comparison accuracy: Îºâ‰¥0.6 vs PT annotations
- âœ… Test all error types (valgus, hiking, ROM, etc.)
- âœ… Validate temporal alignment (slow patient vs fast YouTube video)

### Requirement 6: Simplicity (Frontend & Backend, No Functionality Loss)

**Current Gaps:**
- âŒ No architecture complexity analysis
- âŒ No cyclomatic complexity limits
- âŒ No API simplicity validation
- âŒ Feature bloat risk (authentication, telemetry, device health added without justification)

**Needed:**
- âœ… Cyclomatic complexity <10 per function
- âœ… API surface area minimized (fewer endpoints, fewer props)
- âœ… Every feature justified: "Does this improve comparison accuracy or UX?"
- âœ… Refactoring gate: simplify after each major addition

### Requirement 7: Real-time Performance (No Bottlenecks)

**Current Gaps:**
- âŒ No end-to-end latency budget
- âŒ Performance tested per component, not pipeline
- âŒ No continuous performance CI
- âŒ No profiling under stress (low-end devices, background apps)

**Needed:**
- âœ… Latency budget: 100ms total (allocated per component)
- âœ… End-to-end performance gate after Gate 2
- âœ… Performance CI: fail PR if >10% regression
- âœ… Stress testing: low-end device (iPhone SE), multitasking

---

## ðŸ“Š Revised Gate Structure (Recommendation)

### Proposed Gate Order

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  REVISED GATE SEQUENCE                          â”‚
â”‚              (Accuracy â†’ Performance â†’ Simplicity)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Gate 0: Toolchain Sanity                                      â”‚
â”‚  â”œâ”€ CI/CD, linting, security, build reproducibility            â”‚
â”‚  â””â”€ EXIT: All builds green, no vulnerabilities                 â”‚
â”‚                                                                 â”‚
â”‚  Gate 1: Core Pipeline - Real Implementations (NO MOCKS)       â”‚
â”‚  â”œâ”€ Camera â†’ Pose Detection â†’ Goniometry â†’ Comparison          â”‚
â”‚  â”œâ”€ YouTube video loading and pose extraction                  â”‚
â”‚  â”œâ”€ Patient video capture and pose extraction                  â”‚
â”‚  â”œâ”€ Joint angle calculation (both videos)                      â”‚
â”‚  â”œâ”€ Comparison algorithm (angle deviations, temporal)          â”‚
â”‚  â””â”€ EXIT: End-to-end works (no accuracy validation yet)        â”‚
â”‚                                                                 â”‚
â”‚  Gate 2: Accuracy Validation (THE CRITICAL GATE)               â”‚
â”‚  â”œâ”€ Pose accuracy: Â±5Â° vs synthetic ground truth               â”‚
â”‚  â”œâ”€ Goniometry accuracy: Â±3Â° vs known angles                   â”‚
â”‚  â”œâ”€ Comparison accuracy: Îºâ‰¥0.6 vs PT annotations               â”‚
â”‚  â”œâ”€ Test all error types (valgus, hiking, ROM, etc.)           â”‚
â”‚  â””â”€ EXIT: All accuracy targets met, no false positives >5%     â”‚
â”‚                                                                 â”‚
â”‚  Gate 3: Real-time Performance Optimization                    â”‚
â”‚  â”œâ”€ End-to-end latency <100ms (budget allocation)              â”‚
â”‚  â”œâ”€ Profiling: camera (33ms), pose (30ms), compare (20ms)      â”‚
â”‚  â”œâ”€ Optimize bottlenecks (GPU delegates, zero-copy)            â”‚
â”‚  â”œâ”€ Stress testing: low-end devices, multitasking              â”‚
â”‚  â””â”€ EXIT: <100ms on iPhone SE, 0 dropped frames                â”‚
â”‚                                                                 â”‚
â”‚  Gate 4: Smoothing & False Positive Reduction                  â”‚
â”‚  â”œâ”€ Integrate One-Euro filter (reduce jitter)                  â”‚
â”‚  â”œâ”€ Integrate persistence filtering (temporal validation)      â”‚
â”‚  â”œâ”€ Re-validate accuracy (smoothing shouldn't reduce accuracy) â”‚
â”‚  â””â”€ EXIT: Jitter <3Â°, false positives <2%, accuracy maintained â”‚
â”‚                                                                 â”‚
â”‚  Gate 5: Clinical Thresholds & Research Integration            â”‚
â”‚  â”œâ”€ Map AAOS/IJSPT thresholds to MoveNet model                 â”‚
â”‚  â”œâ”€ Validate thresholds against PT assessments                 â”‚
â”‚  â”œâ”€ Primary joint focus (10Ã— priority boost)                   â”‚
â”‚  â””â”€ EXIT: Thresholds validated, Îºâ‰¥0.65 (improved from Gate 2)  â”‚
â”‚                                                                 â”‚
â”‚  Gate 6: Simplicity & UX Validation                            â”‚
â”‚  â”œâ”€ Steps to feedback: â‰¤5                                      â”‚
â”‚  â”œâ”€ Cognitive load: â‰¤3 (tested with 5 users)                   â”‚
â”‚  â”œâ”€ Error recovery: â‰¤2 steps                                   â”‚
â”‚  â”œâ”€ SetupWizard optimization (lighting, distance)              â”‚
â”‚  â””â”€ EXIT: 5/5 users complete task without help                 â”‚
â”‚                                                                 â”‚
â”‚  Gate 7: Robustness & Device Adaptation                        â”‚
â”‚  â”œâ”€ Real thermal/memory monitoring (native APIs)               â”‚
â”‚  â”œâ”€ Adaptive FPS/resolution based on device health             â”‚
â”‚  â”œâ”€ Edge cases: low light, occlusion, clothing                 â”‚
â”‚  â”œâ”€ Failure modes: camera failure, model load failure          â”‚
â”‚  â””â”€ EXIT: 0 crashes in 100 sessions, graceful degradation      â”‚
â”‚                                                                 â”‚
â”‚  Gate 8: Essential Features Only                               â”‚
â”‚  â”œâ”€ YouTube template library (CRUD)                            â”‚
â”‚  â”œâ”€ Prescription API (PT assigns exercises)                    â”‚
â”‚  â”œâ”€ Audio feedback (TTS, haptics)                              â”‚
â”‚  â”œâ”€ Session history (progress tracking)                        â”‚
â”‚  â””â”€ EXIT: Features work, don't add latency (still <100ms)      â”‚
â”‚                                                                 â”‚
â”‚  Gate 9: Comprehensive Testing & Validation                    â”‚
â”‚  â”œâ”€ Synthetic test dataset (all error types, conditions)       â”‚
â”‚  â”œâ”€ Real patient videos (10-15 annotated by PT)                â”‚
â”‚  â”œâ”€ Accessibility (WCAG AA, screen reader)                     â”‚
â”‚  â”œâ”€ Security (OWASP top 10, no PII leakage)                    â”‚
â”‚  â””â”€ EXIT: All tests pass, ready for beta                       â”‚
â”‚                                                                 â”‚
â”‚  Gate 10: Beta Field Trial                                     â”‚
â”‚  â”œâ”€ 5-10 volunteers (not post-surgical, just testing)          â”‚
â”‚  â”œâ”€ 2-4 weeks usage                                            â”‚
â”‚  â”œâ”€ Collect: crashes, usability, performance                   â”‚
â”‚  â”œâ”€ Iterate based on feedback                                  â”‚
â”‚  â””â”€ EXIT: <1% crash rate, positive feedback â‰¥80%               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Changes from Original Roadmap

| Original | Revised | Rationale |
|----------|---------|-----------|
| Gate 1: Remove Camera Mocks | Gate 1: Core Pipeline (Real) | Broader scope: entire pipeline, not just camera |
| Gate 2: Smoothing first | Gate 2: Accuracy Validation | Validate base accuracy BEFORE optimization |
| No dedicated comparison gate | Gate 2: Comparison as core metric | YouTube comparison is THE value prop |
| Gate 3: Clinical thresholds | Gate 3: Performance | Performance must be architected early |
| Gate 4: Device health | Gate 4: Smoothing | Smoothing comes AFTER accuracy validated |
| Performance tested late | Gate 3: Performance early | Avoid late-stage refactoring |
| No simplicity metrics | Gate 6: Simplicity as gate | UX is core requirement |
| Features scattered | Gate 8: Essential features only | Defer non-critical features |

---

## âœ… Exit Criteria Upgrade (Per Gate)

### Every Gate Must Now Include:

**Accuracy Check:**
- Doesn't degrade accuracy from previous gate
- Comparison accuracy maintained: Îºâ‰¥0.6

**Performance Check:**
- End-to-end latency â‰¤100ms
- No new bottlenecks introduced

**Simplicity Check:**
- Steps to feedback â‰¤5
- Cognitive load â‰¤3 (if UX changed)

**Robustness Check:**
- No new crashes introduced
- Edge cases handled gracefully

---

## ðŸš¨ Critical Action Items

### Immediate (Before Starting Any Gate)

1. **Create Synthetic Test Dataset**
   - 20 videos with ground truth joint angles
   - All error types represented
   - All lighting/clothing/body type variations

2. **Establish Performance Baseline**
   - Measure current end-to-end latency
   - Set budget per component
   - Create CI performance test

3. **Define Accuracy Metrics**
   - Pose: Â±5Â° vs ground truth
   - Goniometry: Â±3Â° vs physical goniometer
   - Comparison: Îºâ‰¥0.6 vs PT

4. **Create Simplicity Scorecard**
   - Steps to feedback
   - Cognitive load scale
   - User testing protocol

### Per Gate

1. **Gate Entry:** Check all prerequisites met
2. **Implementation:** Follow revised gate structure
3. **Testing:** Run all 4 checks (accuracy, performance, simplicity, robustness)
4. **Exit:** Binary GO/NO-GO based on all criteria

---

## ðŸ“ Summary: 6 Hats Insights

**White Hat:** YouTube comparison accuracy is missing as explicit gate
**Red Hat:** Patients need trust (accuracy) and ease (simplicity)
**Black Hat:** Critical risks in accuracy validation, performance, simplicity
**Yellow Hat:** Strong foundation, just needs reordering
**Green Hat:** Accuracy-first gate ordering, latency budgets, synthetic datasets
**Blue Hat:** Revise gate sequence to match criticality

**Recommendation:** Adopt revised 10-gate structure with accuracy and performance first, features last.
